---
title: "Data Cleaning"
author: ""
subtitle: ""
description:  |
  Blog post outlining specifics of the data and how we went about cleaning it.
date: "2024-10-28"
date-modified: "2024-10-28"
draft: FALSE
---

Describe the data in a few sentences/paragraphs.

The first step in the process of loading & cleaning the data was converting the tsv file we found online to a R dataset. We did so through the `read_tsv` tidyverse function, and the process went smoothly. There were no errors, unusual values, or oddly formatted data other than NA, or missing, values. After performing this initial data import, we decided to filter out specific variables that we didn't intend on using in our analysis. These included variables such as PSTRATA and SEUCODE, which are more complex values used to calculate parameters like variance, and WEIGHT, which was the relative weight given to each observation because of the differences in sizes of the dataset in different years. We decided to remove these variables because we figured it would be better if we could control

Weight because we want to do it ourselves

SECUCODE because it relates to PSTRATA

NUM_FU_HHINT, NUM_FU_PERINT because we don't want to use the number of follow-up interviews

Variables ending with "_sub" because we are unsure what "missing  carried back from later waves " means

TIME2VIC_INC_P23PER because don't want to investigate months from PPCS interview to victimization
