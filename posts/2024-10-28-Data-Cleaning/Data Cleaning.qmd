---
title: "Data Cleaning and Loading & Data for Equity"
author: ""
subtitle: ""
description:  |
  Blog post outlining specifics of the data and how we went about cleaning it, additionally discussing the data for equity principles, as well as related article.
date: "2024-10-28"
date-modified: "2024-10-28"
draft: FALSE
---

This week, we finalized the data description and characterization before beginning the process of loading and cleaning the data. The data, which was collected from the Bureau of Justice Statistics (BJS), is a person-level and household-level dataset characterizing police encounter data, emphasizing key variables to study the relationship between police contact and victimization reporting. The raw data consists of 110 variables and 105273 unique observations.

The first step in the process of loading & cleaning the data was converting the tsv file we found online to a R dataset. We did so through the `read_tsv` tidyverse function, and the process went smoothly. There were no errors, unusual values, or oddly formatted data other than NA, or missing, values. After performing this initial data import, we decided to filter out specific variables that we didn't intend on using in our analysis. These included variables such as PSTRATA and SECUCODE, which are more complex values used to calculate parameters like variance, and WEIGHT, which was the relative weight given to each observation due to dataset size differences across different years. We decided to remove variables like these because we realized that, in order to perform analysis of the data ourselves, it would be more accurate and meaningful to calculate these parameters from scratch. That way, we would decrease the risk of performing a biased analysis with data values we didn't fully comprehend.

We also made the systematic decision to remove the variables corresponding to data about follow-up interviews, like NUM_FU_HHINT and NUM_FU_PERINT. We did so because we currently don't intend to use that data in our analysis. Similarly, we decided to systematically remove the variable TIME2VIC_INC_P23PER because we don't want to investigate data about the time between PPCS interview and victimization.

Finally, we were forced to exclude certain variables from the dataset that contained values we didn't understand. For example, all variables that ended with "_sub" were excluded because we were unsure what the description "missing carried back from later waves" from the data info sheet meant.

An important next step in the data cleaning process was exploring the data through barplots showing the distributions for specific variables and boxplots showing outliers. This would aid us in our analysis and further steps when working with the data. As an example, here is a function used to create boxplots:

create_outlier_boxplot <- function(data, col_name) {
  ggplot(data, aes_string(y = col_name)) +
    geom_boxplot(outlier.color = "red",   
                 outlier.shape = 16,      
                 outlier.size = 2) +      
    labs(title = paste("Boxplot of", col_name, "with Outliers"),
         y = col_name) +
    theme_minimal()
}

Data For Equity Principles:

Beneficence:
The dataset we are working on is about crimes and how interactions with police can influence how, why, or if people report them. It is important to us to not misrepresent a certain group of people as more prone to positive or negative interactions with police, as that can reflect a high degree of personal bias. We must represent the data objectively, discussing its implications and results within a wider scope and context. Nevertheless, there are always variables left out of scope that can influence the results. 

Respect for Persons:
The analysis that we aim to do for this dataset is by no means definitive, and it leaves us with many open-ended questions and perhaps concerns. We do not want to bias the viewers of this analysis, and we give them the power to make their own decisions about this data. Holding an unbiased persective also allows usgiving respect to the groups showcased in the data, as we do not want to misrepresent their data.
