---
title: "Data Cleaning and Loading & Data for Equity"
author: ""
subtitle: ""
description:  |
  Blog post outlining specifics of the data and how we went about cleaning it, additionally discussing the data for equity principles, as well as related article.
date: "2024-10-28"
date-modified: "2024-10-28"
draft: FALSE
---

Describe the data in a few sentences/paragraphs.

The first step in the process of loading & cleaning the data was converting the tsv file we found online to a R dataset. We did so through the `read_tsv` tidyverse function, and the process went smoothly. There were no errors, unusual values, or oddly formatted data other than NA, or missing, values. After performing this initial data import, we decided to filter out specific variables that we didn't intend on using in our analysis. These included variables such as PSTRATA and SEUCODE, which are more complex values used to calculate parameters like variance, and WEIGHT, which was the relative weight given to each observation because of the differences in sizes of the dataset in different years. We decided to remove these variables because we figured it would be better if we could control.

Additionally, an importnat step in the data cleaning process was to explore teh data with the help of barplot showing distributions for specific variables and boxplots showing outliers. This would aid us in our analysis and furtehr steps when working with the data. Below is a function used to create boxplots:

create_outlier_boxplot <- function(data, col_name) {
  ggplot(data, aes_string(y = col_name)) +
    geom_boxplot(outlier.color = "red",   
                 outlier.shape = 16,      
                 outlier.size = 2) +      
    labs(title = paste("Boxplot of", col_name, "with Outliers"),
         y = col_name) +
    theme_minimal()
}

Data For Equity Principles:

Beneficence:
The dataset we are working on is about crimes and perpetrators of those crimes. The key idea of working with this dataset is to udnerstand who committed the crimes, why and possibly whether it would be likely that they will commit them again in the future. Thus, it is important to us to not misrepresent a certain group of people as the group that is responsible for all crime or even the most of it, there are always additional factors involved apart from a specific statistic of a group commiting more crimes. It is important to represent the data objectively, discussing its implicatons and results within a wider scope and context, signifying that there are always variables left out of scope taht can influence the results nevertheless. 

Respect for Persons:
The analysis that we aim to do for this dataset should by no means be definitive, but still leave open-ended questions and perhaps concerns. We do not want to craete a bias for the viewers of this analysis and give them the power to make their own decisions about this data. It is again important taht we bring this unbiased view as ameans of displaying accurate and unbiased results (giving respect to teh groups showcased in teh data), however also allowing for the viewers the right to consider and decide whetehr they agree with us or not, without forcing any bias on them. 



Weight because we want to do it ourselves

SECUCODE because it relates to PSTRATA

NUM_FU_HHINT, NUM_FU_PERINT because we don't want to use the number of follow-up interviews

Variables ending with "_sub" because we are unsure what "missing  carried back from later waves " means

TIME2VIC_INC_P23PER because don't want to investigate months from PPCS interview to victimization
